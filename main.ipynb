{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mAd0wUwT5Jt"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "!pip install stable-baselines3\n",
        "!pip install highway-env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO, A2C\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='gymnasium.core')\n",
        "\n",
        "class CustomCallback:\n",
        "    def __init__(self):\n",
        "        self.rewards = []\n",
        "        self.collisions = []\n",
        "        self.speeds = []\n",
        "        self.episode_rewards = []\n",
        "        self.episode_collisions = []\n",
        "        self.episode_speeds = []\n",
        "        self.episode_times = []\n",
        "        self.start_time = None\n",
        "\n",
        "    def on_step(self, locals_, globals_):\n",
        "        env = locals_['env']\n",
        "        reward = locals_['rewards']\n",
        "        done = locals_['dones']\n",
        "        info = locals_['infos']\n",
        "\n",
        "        # Track rewards\n",
        "        self.rewards.append(reward[0])\n",
        "\n",
        "        # Track vehicle speed\n",
        "        vehicle = env.get_attr('vehicle')[0]  # Get the controlled vehicle\n",
        "        self.speeds.append(vehicle.speed)\n",
        "\n",
        "        # Track collisions\n",
        "        collision = info[0].get('crashed', False)\n",
        "        self.collisions.append(1 if collision else 0)\n",
        "\n",
        "        # On episode end\n",
        "        if done[0]:\n",
        "            # Calculate total travel time (number of steps taken)\n",
        "            self.episode_rewards.append(np.sum(self.rewards))\n",
        "            self.episode_collisions.append(np.sum(self.collisions))\n",
        "            self.episode_speeds.append(np.mean(self.speeds))\n",
        "            self.episode_times.append(len(self.rewards))\n",
        "            self.rewards = []\n",
        "            self.collisions = []\n",
        "            self.speeds = []\n",
        "\n",
        "        return True\n",
        "\n",
        "    def smooth_data(self, data, window_size=10):\n",
        "        \"\"\" Apply a rolling average to smooth data. \"\"\"\n",
        "        return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "    def aggregate_data(self, data, bin_size=10):\n",
        "        \"\"\"Aggregate data by calculating the average in bins.\"\"\"\n",
        "        return [np.mean(data[i:i+bin_size]) for i in range(0, len(data), bin_size)]\n",
        "\n",
        "    def get_stats(self):\n",
        "        def compute_stats(data):\n",
        "            return {\n",
        "                'mean': np.mean(data),\n",
        "                'min': np.min(data),\n",
        "                'max': np.max(data)\n",
        "            }\n",
        "        stats = {\n",
        "            'reward': compute_stats(self.episode_rewards),\n",
        "            'collision': compute_stats(self.episode_collisions),\n",
        "            'speed': compute_stats(self.episode_speeds),\n",
        "            'travel_time': compute_stats(self.episode_times)\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "    def plot_metrics(self, title=\"Performance Metrics\"):\n",
        "        episodes = range(len(self.episode_rewards))\n",
        "\n",
        "        # Smooth and aggregate data for better visualization\n",
        "        reward_smoothed = self.smooth_data(self.episode_rewards)\n",
        "        collision_smoothed = self.smooth_data(self.episode_collisions)\n",
        "        speed_smoothed = self.smooth_data(self.episode_speeds)\n",
        "        time_smoothed = self.smooth_data(self.episode_times)\n",
        "\n",
        "        reward_aggregated = self.aggregate_data(self.episode_rewards)\n",
        "        collision_aggregated = self.aggregate_data(self.episode_collisions)\n",
        "        speed_aggregated = self.aggregate_data(self.episode_speeds)\n",
        "        time_aggregated = self.aggregate_data(self.episode_times)\n",
        "\n",
        "        plt.figure(figsize=(20, 10))\n",
        "\n",
        "        # Plot average reward per episode\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(episodes[:len(reward_smoothed)], reward_smoothed, label='Smoothed Reward ', color='blue')\n",
        "        plt.plot(range(0, len(reward_aggregated)*10, 10), reward_aggregated, label='Aggregated Reward ', color='cyan', linestyle='--')\n",
        "        plt.axhline(np.mean(self.episode_rewards), color='red', linestyle='--', label='Average Reward')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Total Reward')\n",
        "        plt.title('Reward per Episode')\n",
        "        plt.legend()\n",
        "        plt.ylim(bottom=0)\n",
        "\n",
        "        # Plot number of collisions per episode\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(episodes[:len(collision_smoothed)], collision_smoothed, label='Smoothed Collisions', color='green')\n",
        "        plt.plot(range(0, len(collision_aggregated)*10, 10), collision_aggregated, label='Aggregated Collisions ', color='lime', linestyle='--')\n",
        "        plt.axhline(np.mean(self.episode_collisions), color='red', linestyle='--', label='Average Collisions')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Number of Collisions')\n",
        "        plt.title('Collisions per Episode')\n",
        "        plt.legend()\n",
        "        plt.ylim(bottom=0)\n",
        "\n",
        "        # Plot average speed per episode\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.plot(episodes[:len(speed_smoothed)], speed_smoothed, label='Smoothed Speed per episode', color='orange')\n",
        "        plt.plot(range(0, len(speed_aggregated)*10, 10), speed_aggregated, label='Aggregated Speed per episode', color='gold', linestyle='--')\n",
        "        plt.axhline(np.mean(self.episode_speeds), color='red', linestyle='--', label='Average Speed')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Speed (m/s)')\n",
        "        plt.title('Speed per Episode')\n",
        "        plt.legend()\n",
        "        plt.ylim(bottom=0)\n",
        "\n",
        "        # Plot total travel time per episode\n",
        "        plt.subplot(2, 2, 4)\n",
        "        plt.plot(episodes[:len(time_smoothed)], time_smoothed, label='Smoothed Travel Time per episode', color='purple')\n",
        "        plt.plot(range(0, len(time_aggregated)*10, 10), time_aggregated, label='Aggregated Travel Time per episode', color='violet', linestyle='--')\n",
        "        plt.axhline(np.mean(self.episode_times), color='red', linestyle='--', label='Average Travel Time')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Travel Time (timesteps)')\n",
        "        plt.title('Travel Time per Episode')\n",
        "        plt.legend()\n",
        "        plt.ylim(bottom=0)  # Set lower limit to 0 for better visibility\n",
        "        plt.suptitle(title, fontsize=16, y=0.01)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make('intersection-v0')\n",
        "\n",
        "# Wrap the environment with DummyVecEnv for Stable Baselines3\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# Create the PPO and A2C models\n",
        "ppo_model = PPO('MlpPolicy', env, verbose=1)\n",
        "a2c_model = A2C('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Create the custom callbacks\n",
        "ppo_callback = CustomCallback()\n",
        "a2c_callback = CustomCallback()\n",
        "\n",
        "# Train the models\n",
        "ppo_model.learn(total_timesteps=500, callback=ppo_callback.on_step)\n",
        "a2c_model.learn(total_timesteps=500, callback=a2c_callback.on_step)\n",
        "\n",
        "# Save the models\n",
        "ppo_model.save(\"ppo_intersection\")\n",
        "a2c_model.save(\"a2c_intersection\")\n",
        "\n",
        "# Load the models (optional, if you want to use the saved models later)\n",
        "ppo_model = PPO.load(\"ppo_intersection\", env=env)\n",
        "a2c_model = A2C.load(\"a2c_intersection\", env=env)\n",
        "\n",
        "# Evaluate the models for a fixed number of episodes\n",
        "def evaluate_model(model, env, callback, num_episodes=50):\n",
        "    obs = env.reset()\n",
        "    for i in range(num_episodes):\n",
        "        done = False\n",
        "        while not done:\n",
        "            action, _states = model.predict(obs)\n",
        "            obs, rewards, done, info = env.step(action)\n",
        "            callback.on_step({'rewards': rewards, 'dones': done, 'infos': info, 'env': env}, {})\n",
        "            if done:\n",
        "                obs = env.reset()\n",
        "\n",
        "# Evaluate PPO\n",
        "evaluate_model(ppo_model, env, ppo_callback, num_episodes=50)\n",
        "# Evaluate A2C\n",
        "evaluate_model(a2c_model, env, a2c_callback, num_episodes=50)\n",
        "\n",
        "\n",
        "ppo_callback.plot_metrics(title=\"Performance Metrics for PPO\")\n",
        "a2c_callback.plot_metrics(title=\"Performance Metrics for A2C\")\n",
        "\n",
        "\n",
        "def calculate_normalized_score(stats, alpha1, alpha2, alpha3, alpha4):\n",
        "    def normalize(value, min_val, max_val):\n",
        "        return (value - min_val) / (max_val - min_val)\n",
        "\n",
        "    reward_norm = normalize(stats['reward']['mean'], min_reward, max_reward)\n",
        "    collision_norm = normalize(stats['collision']['mean'], min_collision, max_collision)\n",
        "    speed_norm = normalize(stats['speed']['mean'], min_speed, max_speed)\n",
        "    travel_time_norm = normalize(stats['travel_time']['mean'], min_travel_time, max_travel_time)\n",
        "\n",
        "    score = (alpha1 * reward_norm) + (alpha2 * (1 - collision_norm)) + (alpha3 * speed_norm) + (alpha4 * (1 - travel_time_norm))\n",
        "    return score\n",
        "\n",
        "\n",
        "ppo_stats = ppo_callback.get_stats()\n",
        "a2c_stats = a2c_callback.get_stats()\n",
        "\n",
        "\n",
        "min_reward = min(ppo_stats['reward']['min'], a2c_stats['reward']['min'])\n",
        "max_reward = max(ppo_stats['reward']['max'], a2c_stats['reward']['max'])\n",
        "min_collision = min(ppo_stats['collision']['min'], a2c_stats['collision']['min'])\n",
        "max_collision = max(ppo_stats['collision']['max'], a2c_stats['collision']['max'])\n",
        "min_speed = min(ppo_stats['speed']['min'], a2c_stats['speed']['min'])\n",
        "max_speed = max(ppo_stats['speed']['max'], a2c_stats['speed']['max'])\n",
        "min_travel_time = min(ppo_stats['travel_time']['min'], a2c_stats['travel_time']['min'])\n",
        "max_travel_time = max(ppo_stats['travel_time']['max'], a2c_stats['travel_time']['max'])\n",
        "\n",
        "# Hyperparameters for the scoring function (sum to 1)\n",
        "alpha1, alpha2, alpha3, alpha4 = 0.3, 0.2, 0.3, 0.2\n",
        "\n",
        "# Calculate scores\n",
        "ppo_score = calculate_normalized_score(ppo_stats, alpha1, alpha2, alpha3, alpha4)\n",
        "a2c_score = calculate_normalized_score(a2c_stats, alpha1, alpha2, alpha3, alpha4)\n",
        "\n",
        "# Print the model with the higher score\n",
        "if ppo_score > a2c_score:\n",
        "    print(f\"PPO has a higher score: {ppo_score}\")\n",
        "else:\n",
        "    print(f\"A2C has a higher score: {a2c_score}\")\n"
      ],
      "metadata": {
        "id": "3nlS2W9KUDwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}